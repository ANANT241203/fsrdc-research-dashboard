{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pW6LEbRcMGkq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SloLjXIrMJLH"
      },
      "outputs": [],
      "source": [
        "excel = pd.read_excel('ResearchOutputs.xlsx')\n",
        "step1 = pd.read_excel('ResearchOutputs_Group3.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9kp_Qc4d1rQ",
        "outputId": "5b91c714-145c-4da7-bd16-d424a1d350c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1735 entries, 0 to 1734\n",
            "Data columns (total 17 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   ProjectID         1735 non-null   int64  \n",
            " 1   ProjectStatus     1735 non-null   object \n",
            " 2   ProjectTitle      1735 non-null   object \n",
            " 3   ProjectRDC        1735 non-null   object \n",
            " 4   ProjectStartYear  1735 non-null   int64  \n",
            " 5   ProjectEndYear    1355 non-null   float64\n",
            " 6   ProjectPI         1735 non-null   object \n",
            " 7   OutputTitle       1734 non-null   object \n",
            " 8   OutputBiblio      1735 non-null   object \n",
            " 9   OutputType        1735 non-null   object \n",
            " 10  OutputStatus      1734 non-null   object \n",
            " 11  OutputVenue       1488 non-null   object \n",
            " 12  OutputYear        1731 non-null   float64\n",
            " 13  OutputMonth       353 non-null    object \n",
            " 14  OutputVolume      462 non-null    object \n",
            " 15  OutputNumber      842 non-null    object \n",
            " 16  OutputPages       387 non-null    object \n",
            "dtypes: float64(2), int64(2), object(13)\n",
            "memory usage: 230.6+ KB\n"
          ]
        }
      ],
      "source": [
        "excel.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juO-sO14M3qw",
        "outputId": "8cf31876-250a-4268-9245-5a0bf0e724d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2393 entries, 0 to 2392\n",
            "Data columns (total 18 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   DOI           2393 non-null   object \n",
            " 1   OutputTitle   2393 non-null   object \n",
            " 2   OutputBiblio  2393 non-null   object \n",
            " 3   OutputType    2356 non-null   object \n",
            " 4   OutputStatus  2393 non-null   object \n",
            " 5   OutputVenue   2393 non-null   object \n",
            " 6   OutputYear    2393 non-null   float64\n",
            " 7   OutputMonth   2085 non-null   float64\n",
            " 8   OutputVolume  2060 non-null   object \n",
            " 9   OutputNumber  1835 non-null   object \n",
            " 10  OutputPages   1319 non-null   object \n",
            " 11  author        2393 non-null   object \n",
            " 12  Proj ID       2393 non-null   object \n",
            " 13  Status        2393 non-null   object \n",
            " 14  RDC           2393 non-null   object \n",
            " 15  Start Year    2393 non-null   object \n",
            " 16  End Year      1723 non-null   object \n",
            " 17  PI            2393 non-null   object \n",
            "dtypes: float64(2), object(16)\n",
            "memory usage: 336.6+ KB\n"
          ]
        }
      ],
      "source": [
        "step1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99Trci0HN2xg",
        "outputId": "7ecd6fc7-3e91-443d-d237-bc1d1c5d0e12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1784 entries, 0 to 1783\n",
            "Data columns (total 34 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   ProjectID         1784 non-null   int64  \n",
            " 1   ProjectStatus     1784 non-null   object \n",
            " 2   ProjectTitle      1784 non-null   object \n",
            " 3   ProjectRDC        1784 non-null   object \n",
            " 4   ProjectStartYear  1784 non-null   int64  \n",
            " 5   ProjectEndYear    1390 non-null   float64\n",
            " 6   ProjectPI         1784 non-null   object \n",
            " 7   OutputTitle       1783 non-null   object \n",
            " 8   OutputBiblio_x    1784 non-null   object \n",
            " 9   OutputType_x      1784 non-null   object \n",
            " 10  OutputStatus_x    1783 non-null   object \n",
            " 11  OutputVenue_x     1532 non-null   object \n",
            " 12  OutputYear_x      1780 non-null   float64\n",
            " 13  OutputMonth_x     364 non-null    object \n",
            " 14  OutputVolume_x    478 non-null    object \n",
            " 15  OutputNumber_x    871 non-null    object \n",
            " 16  OutputPages_x     400 non-null    object \n",
            " 17  DOI               191 non-null    object \n",
            " 18  OutputBiblio_y    191 non-null    object \n",
            " 19  OutputType_y      189 non-null    object \n",
            " 20  OutputStatus_y    191 non-null    object \n",
            " 21  OutputVenue_y     191 non-null    object \n",
            " 22  OutputYear_y      191 non-null    float64\n",
            " 23  OutputMonth_y     103 non-null    float64\n",
            " 24  OutputVolume_y    99 non-null     object \n",
            " 25  OutputNumber_y    85 non-null     object \n",
            " 26  OutputPages_y     105 non-null    object \n",
            " 27  author            191 non-null    object \n",
            " 28  Proj ID           191 non-null    float64\n",
            " 29  Status            191 non-null    object \n",
            " 30  RDC               191 non-null    object \n",
            " 31  Start Year        191 non-null    object \n",
            " 32  End Year          172 non-null    object \n",
            " 33  PI                191 non-null    object \n",
            "dtypes: float64(5), int64(2), object(27)\n",
            "memory usage: 474.0+ KB\n"
          ]
        }
      ],
      "source": [
        "step1['Proj ID'] = step1['Proj ID'].str.split(',')\n",
        "\n",
        "#Strip whitespace\n",
        "step1 = step1.explode('Proj ID')\n",
        "step1['Proj ID'] = step1['Proj ID'].str.strip()\n",
        "\n",
        "#Convert back to numeric\n",
        "step1['Proj ID'] = pd.to_numeric(step1['Proj ID'], errors='coerce')\n",
        "\n",
        "merged = pd.merge(excel,step1,how='left',left_on=['ProjectID', 'OutputTitle'],right_on=['Proj ID', 'OutputTitle'])\n",
        "merged.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oxS1xMh-Pqtd"
      },
      "outputs": [],
      "source": [
        "columns_for_pca = [\n",
        "    'ProjectStartYear', 'ProjectEndYear', 'OutputYear_x', 'OutputPages_x',\n",
        "    'OutputType_x', 'OutputStatus_x', 'ProjectRDC'\n",
        "]\n",
        "\n",
        "# Drop rows with missing values\n",
        "df_pca = merged[columns_for_pca].dropna()\n",
        "\n",
        "# Extract first number from OutputPages (e.g., \"84-96\" â†’ 84)\n",
        "df_pca['OutputPages_x'] = df_pca['OutputPages_x'].astype(str).str.extract(r'(\\d+)').astype(float)\n",
        "\n",
        "# Define feature types\n",
        "numerical_features = ['ProjectStartYear', 'ProjectEndYear', 'OutputYear_x', 'OutputPages_x']\n",
        "categorical_features = ['OutputType_x', 'OutputStatus_x', 'ProjectRDC']\n",
        "\n",
        "# Preprocessing and PCA pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numerical_features),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('pca', PCA(n_components=2))\n",
        "])\n",
        "\n",
        "# Fit and transform PCA\n",
        "pca_result = pipeline.fit_transform(df_pca)\n",
        "\n",
        "# Build a DataFrame for visualization\n",
        "pca_df = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
        "pca_df['OutputType_x'] = df_pca['OutputType_x'].values\n",
        "\n",
        "# Plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "TmCt5yYdvzdI",
        "outputId": "95272024-b940-446d-d641-fc53a9900e67"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='OutputType_x', alpha=0.7)\n",
        "plt.title(\"PCA of FSRDC Research Outputs\")\n",
        "plt.xlabel(\"Principal Component 1\")\n",
        "plt.ylabel(\"Principal Component 2\")\n",
        "plt.legend(title=\"Output Type\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "UZRl3boao-6i",
        "outputId": "41ea37e7-964d-456b-e354-b865625e2d06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OutputType_x</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>JA</th>\n",
              "      <td>368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WP</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BC</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JA</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MI</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "OutputType_x\n",
              "JA     368\n",
              "WP       4\n",
              "BC       2\n",
              " JA      1\n",
              "MI       1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = merged.copy()\n",
        "\n",
        "df['OutputPages_x'] = df['OutputPages_x'].astype(str).str.extract(r'(\\d+)').astype(float)\n",
        "\n",
        "# Drop rows with missing values in required columns\n",
        "cols = [\n",
        "    'ProjectStartYear', 'ProjectEndYear',\n",
        "    'OutputYear_x', 'OutputPages_x',\n",
        "    'OutputStatus_x', 'ProjectRDC', 'OutputType_x'\n",
        "]\n",
        "df = df[cols].dropna()\n",
        "\n",
        "df['OutputType_x'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3ba4qwnQQGi",
        "outputId": "d26072a7-a142-4a6f-a841-8e4b5b610855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Distribution OutputType_x\n",
            "JA    368\n",
            "WP      4\n",
            "BC      2\n",
            "Name: count, dtype: int64\n",
            "Resampled Class Distribution:\n",
            " OutputType_x\n",
            "JA    368\n",
            "WP    368\n",
            "BC    368\n",
            "Name: count, dtype: int64\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          BC       1.00      1.00      1.00        73\n",
            "          JA       0.99      1.00      0.99        79\n",
            "          WP       1.00      0.99      0.99        69\n",
            "\n",
            "    accuracy                           1.00       221\n",
            "   macro avg       1.00      1.00      1.00       221\n",
            "weighted avg       1.00      1.00      1.00       221\n",
            "\n",
            "Confusion Matrix:\n",
            " [[73  0  0]\n",
            " [ 0 79  0]\n",
            " [ 0  1 68]]\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import pandas as pd\n",
        "\n",
        "# Use your merged DataFrame\n",
        "df = merged.copy()\n",
        "\n",
        "# Clean OutputPages_x\n",
        "df['OutputPages_x'] = df['OutputPages_x'].astype(str).str.extract(r'(\\d+)').astype(float)\n",
        "\n",
        "# Drop rows with missing values in required columns\n",
        "cols = [\n",
        "    'ProjectStartYear', 'ProjectEndYear',\n",
        "    'OutputYear_x', 'OutputPages_x',\n",
        "    'OutputStatus_x', 'ProjectRDC', 'OutputType_x'\n",
        "]\n",
        "df = df[cols].dropna()\n",
        "\n",
        "# Drop classes with only 1 count\n",
        "class_counts = df['OutputType_x'].value_counts()\n",
        "df = df[df['OutputType_x'].isin(class_counts[class_counts > 1].index)]\n",
        "\n",
        "# Check class distribution after dropping\n",
        "print(\"Class Distribution\", df['OutputType_x'].value_counts())\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(columns='OutputType_x')\n",
        "y = df['OutputType_x']\n",
        "\n",
        "# Preprocessing: Encoding categorical features first\n",
        "numerical = ['ProjectStartYear', 'ProjectEndYear', 'OutputYear_x', 'OutputPages_x']\n",
        "categorical = ['OutputStatus_x', 'ProjectRDC']\n",
        "\n",
        "# OneHotEncode categorical columns\n",
        "X_encoded = pd.get_dummies(X, columns=categorical, drop_first=True)\n",
        "\n",
        "# Apply SMOTE with k_neighbors=1\n",
        "smote = SMOTE(random_state=42, k_neighbors=1)\n",
        "X_res, y_res = smote.fit_resample(X_encoded, y)\n",
        "\n",
        "# Display balanced class distribution\n",
        "print(\"Resampled Class Distribution:\\n\", y_res.value_counts())\n",
        "\n",
        "# Train/test split on resampled data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
        "\n",
        "# Modeling pipeline (no need for OneHotEncoder here)\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numerical)\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Fit model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AB1U0fuyRd1l"
      },
      "outputs": [],
      "source": [
        "# Shared Setups for different Clustering examples\n",
        "\n",
        "# Select relevant features for clustering\n",
        "features = [\n",
        "    'ProjectStartYear', 'ProjectEndYear', 'OutputYear_x', 'OutputPages_x',\n",
        "    'ProjectRDC', 'OutputStatus_x', 'OutputType_x'\n",
        "]\n",
        "\n",
        "# Clean and prepare\n",
        "df_cluster = merged[features].dropna()\n",
        "df_cluster['OutputPages_x'] = df_cluster['OutputPages_x'].astype(str).str.extract(r'(\\d+)').astype(float)\n",
        "\n",
        "# Identify feature types\n",
        "numerical = ['ProjectStartYear', 'ProjectEndYear', 'OutputYear_x', 'OutputPages_x']\n",
        "categorical = ['ProjectRDC', 'OutputStatus_x', 'OutputType_x']\n",
        "\n",
        "# Use default sparse=True to avoid version issues\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numerical),\n",
        "    ('cat', encoder, categorical)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gjXw6kbyhxX0"
      },
      "outputs": [],
      "source": [
        "# KMeans Clustering (3 clusters)\n",
        "\n",
        "pipeline_k3 = Pipeline([\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('cluster', KMeans(n_clusters=3, random_state=42))\n",
        "])\n",
        "\n",
        "df_cluster['Cluster_K3'] = pipeline_k3.fit_predict(df_cluster)\n",
        "\n",
        "# PCA for visualization\n",
        "X_2D_k3 = PCA(n_components=2).fit_transform(\n",
        "    pipeline_k3.named_steps['preprocessing'].transform(df_cluster).toarray()\n",
        "    if hasattr(pipeline_k3.named_steps['preprocessing'].transform(df_cluster), 'toarray')\n",
        "    else pipeline_k3.named_steps['preprocessing'].transform(df_cluster)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "t51Fz-dJvviZ",
        "outputId": "b43f47d2-3be0-4753-c238-bd657826b2dd"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=X_2D_k3[:, 0], y=X_2D_k3[:, 1], hue=df_cluster['Cluster_K3'], palette='tab10')\n",
        "plt.title(\"KMeans Clustering (3 Clusters)\")\n",
        "plt.xlabel(\"Project Trait Axis 1\")\n",
        "plt.ylabel(\"Project Trait Axis 2\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tevHHA6bh0JK"
      },
      "outputs": [],
      "source": [
        "# KMeans Clustering (4 clusters)\n",
        "\n",
        "pipeline_k4 = Pipeline([\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('cluster', KMeans(n_clusters=4, random_state=42))\n",
        "])\n",
        "\n",
        "df_cluster['Cluster_K4'] = pipeline_k4.fit_predict(df_cluster)\n",
        "\n",
        "X_2D_k4 = PCA(n_components=2).fit_transform(\n",
        "    pipeline_k4.named_steps['preprocessing'].transform(df_cluster).toarray()\n",
        "    if hasattr(pipeline_k4.named_steps['preprocessing'].transform(df_cluster), 'toarray')\n",
        "    else pipeline_k4.named_steps['preprocessing'].transform(df_cluster)\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "xGUbEzZWvt4J",
        "outputId": "8f0b62c9-f948-4596-95b5-294747f63722"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=X_2D_k4[:, 0], y=X_2D_k4[:, 1], hue=df_cluster['Cluster_K4'], palette='tab10')\n",
        "plt.title(\"KMeans Clustering (4 Clusters)\")\n",
        "plt.xlabel(\"Project Trait Axis 1\")\n",
        "plt.ylabel(\"Project Trait Axis 2\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "s4jO8drWiBpC"
      },
      "outputs": [],
      "source": [
        "# DBSCAN Clustering\n",
        "\n",
        "# Manual transformation for DBSCAN\n",
        "X_transformed = preprocessor.fit_transform(df_cluster)\n",
        "X_dense = X_transformed.toarray() if hasattr(X_transformed, \"toarray\") else X_transformed\n",
        "\n",
        "db = DBSCAN(eps=2.5, min_samples=3)\n",
        "df_cluster['Cluster_DBSCAN'] = db.fit_predict(X_dense)\n",
        "\n",
        "X_2D_db = PCA(n_components=2).fit_transform(X_dense)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "TGzEWPWhvsa-",
        "outputId": "efc45ef8-4100-4f24-f3fc-34cc5b744511"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=X_2D_db[:, 0], y=X_2D_db[:, 1], hue=df_cluster['Cluster_DBSCAN'], palette='tab10')\n",
        "plt.title(\"DBSCAN Clustering of Projects\")\n",
        "plt.xlabel(\"Project Trait Axis 1\")\n",
        "plt.ylabel(\"Project Trait Axis 2\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmKhpZe9iRzt",
        "outputId": "b1b7368c-2320-43d9-92e4-c6063c58a26e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " LDA Topics:\n",
            "Topic 1: effects | insurance | level | health | census | firms | data | evidence\n",
            "Topic 2: market | essays | business | innovation | productivity | labor | firm | firms\n",
            "Topic 3: plant | effects | business | manufacturing | evidence | productivity | international | trade\n",
            "Topic 4: market | states | united | earnings | new | evidence | income | labor\n",
            "Topic 5: employment | industry | energy | market | dynamics | evidence | performance | firm\n"
          ]
        }
      ],
      "source": [
        "# Text Processing on merged['OutputTitle']\n",
        "\n",
        "# Drop missing or invalid titles\n",
        "df_text = merged[['OutputTitle']].dropna()\n",
        "df_text['OutputTitle'] = df_text['OutputTitle'].astype(str)\n",
        "\n",
        "# Text Clustering with TF-IDF + KMeans\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.85, min_df=2, ngram_range=(1, 2))\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df_text['OutputTitle'])\n",
        "\n",
        "# Cluster using KMeans\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "df_text['TFIDF_Cluster'] = kmeans.fit_predict(X_tfidf)\n",
        "\n",
        "# Reduce to 2D for plotting\n",
        "X_pca = PCA(n_components=2).fit_transform(X_tfidf.toarray())\n",
        "df_text['PC1'] = X_pca[:, 0]\n",
        "df_text['PC2'] = X_pca[:, 1]\n",
        "\n",
        "\n",
        "# Topic Modeling with LDA\n",
        "\n",
        "count_vectorizer = CountVectorizer(stop_words='english', max_df=0.85, min_df=3)\n",
        "X_counts = count_vectorizer.fit_transform(df_text['OutputTitle'])\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
        "lda.fit(X_counts)\n",
        "\n",
        "# Print top words per topic\n",
        "print(\"\\n LDA Topics:\")\n",
        "words = count_vectorizer.get_feature_names_out()\n",
        "for i, topic in enumerate(lda.components_):\n",
        "    top_words = [words[i] for i in topic.argsort()[-8:]]\n",
        "    print(f\"Topic {i+1}: {' | '.join(top_words)}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "DUyvRZDRvEpB",
        "outputId": "90328ab4-0660-468a-94b9-8e52058db5f8"
      },
      "outputs": [],
      "source": [
        "# Visualize Clusters\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df_text, x='PC1', y='PC2', hue='TFIDF_Cluster', palette='tab10')\n",
        "plt.title(\"TF-IDF Clustering of Output Titles\")\n",
        "plt.xlabel(\"Semantic Axis 1\")\n",
        "plt.ylabel(\"Semantic Axis 2\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "sK3w-vbgv2IO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
